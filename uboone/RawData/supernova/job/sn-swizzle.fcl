#include "messageservice.fcl"
#include "databaseutil_microboone.fcl"
#include "geometry_microboone.fcl"
#include "detectorclocks_microboone.fcl"
#include "opticaldetectormodules_microboone.fcl"

process_name: SupernovaAssembler

services:
{
  # Load the service that manages root files for histograms.
  # Any histograms or n-tuples that you create in the program will be
  # written to this file. You can override the file name with the -T
  # option on the command line; e.g.,
  #  lar -c AnalysisExample.fcl -T myhistograms.root -s myinput.root
  TFileService:           { fileName: "SN_Statistics.root" }

  # This constrols the display in the output of how long each job step
  # takes for each event. A lot of configuration can be added: details at
  # https://cdcvs.fnal.gov/redmine/projects/art/wiki/TimeTracker#TimeTracker

  TimeTracker:            {}

  # This parameter controls the level of descriptive output from
  # various LArSoft modules. For a list of different message levels,
  # see ${LARDATA_DIR}/job/messageservice.fcl. For most jobs this is
  # set to standard_warning; here it is set to standard_info because I
  # write some LogInfo messages in the analysis module for
  # demonstration purposes.

  DatabaseUtil:           @local::microboone_database
  message:                @local::standard_info
  
  ExptGeoHelperInterface: @local::microboone_geometry_helper
  Geometry:               @local::microboone_geo
    UBOpReadoutMap:         @local::microboone_opreadoutmap
  DetectorClocksService:  @local::microboone_detectorclocks

} # services


# The 'source' section tells the script to expect an input file with art::Event records.
# Note that the name of the input file is not included here. You specify that on the
# command line when you run this script; e.g.,
#    lar -c AnalysisExample.fcl -s myinput.root
# The file "myinput.root" is assumed to have been created by a previous LArSoft job.

source:
{
  fileNames:       [ "supernova.ubdaq" ]
  module_type: SnFileSource

  # Number of events to analyze; "-1" means all of the events in the input
  # file. You can override this value with the "-n" option on the command line. 
  maxEvents:  -1 

  # I've commented this out, but if you really want to include the name of
  # an input file in this script, here's how you do it.
  # fileNames: ["myinput.root"]
}
outputs:
{
 out1:
  {
   module_type: RootOutput
   fileName: "%ifb-%tc-sn-%#.root"
      # fileName: "output.root"
   dataTier: "raw"
   compressionLevel: 3
   saveMemoryObjectThreshold: 0
   fileProperties: {
     maxInputFiles: 1
     granularity: "InputFile"
    }
  }
}

# The 'physics' section defines and configures some modules to do work on each event.
# First modules are defined; they are scheduled later. Modules are grouped by type.
physics:
{
  # Define the variables we'll need to run for this analysis program.

  # producers: {
  #   snhit: {
  #     module_type: "SnHitFinder"
  #   }
  # }

  analyzers:
  {
    dump: {
      module_type: "TriggerDumper"
      HardwareTriggerProducer: "sndaq"
      SoftwareTriggerProducer: "sndaq"
      NumDump: 1000
    }
    
  }

  # Schedule job step(s) for execution by defining the analysis module
  # for this job. An 'analysis' module (as opposed to a 'producer' or
  # a 'filter') does not alter the contents of events in the input
  # file, nor does it create any events as output. Any step names
  # listed here must match a name in the 'analyzers' section above.

  # path1: [ snhit ]
  path2: [ dump, out1 ]
  # stream1:   [ path0, path1, out1 ]
  # trigger_paths: [ path1  ]
  end_paths: [  path2 ]
}
services.DetectorClocksService.InheritClockConfig: false
services.DetectorClocksService.TrigModuleName: "sndaq"

# services.DetectorPropertiesService.NumberTimeSamples:                  6400
# services.DetectorPropertiesService.ReadOutWindowSize:                  6400
# services.DetectorClocksService.InheritClockConfig:                     false
# services.DetectorClocksService.TriggerOffsetTPC:                       -0.400e3

# for running at fnal:
services.DatabaseUtil.DBHostName:    "ifdbprod2.fnal.gov"
services.DatabaseUtil.DBName:        "hootgibson_prod"
services.DatabaseUtil.DBUser:        "uboonedaq_web"
services.DatabaseUtil.Port:          5444
services.DatabaseUtil.PassFileName:  "uboonedb_passwd"  # name of password file. searched for using env var FW_SEARCH_PATH
services.DatabaseUtil.ToughErrorTreatment: true
services.DatabaseUtil.ShouldConnect: true
services.DatabaseUtil.TableName: "main_run"

#laptop:
#services.DatabaseUtil.DBHostName:    "localhost"
#services.DatabaseUtil.DBName:        "hootgibson_prod"
#services.DatabaseUtil.DBUser:        "tagg"
#services.DatabaseUtil.Port:          5432
#services.DatabaseUtil.PassFileName:  "psql_password_empty"  # name of password file. searched for using env var FW_SEARCH_PATH
#services.DatabaseUtil.ToughErrorTreatment: true
#services.DatabaseUtil.ShouldConnect: true
#services.DatabaseUtil.TableName: "main_run"
